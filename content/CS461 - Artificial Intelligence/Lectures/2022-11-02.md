---
title: "2022-11-02"
date: 2022-11-01
parent: [[CS461 - Artificial Intelligence/Lectures/_index]]
tags:
- lecture
- cs461
---

# Machine Learning

* **Unsupervised**
	* Clustering is a common goal: tell us what category things fall into
* **Supervised**: we generally have at least *some* idea of what we're looking for or a task we want to carry out
* **Reinforcement**: ask the system to make choices, at some point give feedback on how good that choice was
* **Decision Trees**

<div class="svg">

![[Excalidraw/Drawing 2022-11-02 13.19.08.excalidraw.svg]]

</div>

> [!ERROR] ERROR
> 
> Textbook calls the **test** set a *validation* set - this is incorrect!

* Training Data
* Test Data
	* Used to measure error while training a model
	* Helps prevent *overfitting*
* Validation Data
	* No machine learning model **ever** sees this stuff!
	* Makes sure you came out with something consistent

The **target function** - thing we're trying to measure - should also have a small number of variables.

We might also have missing data, input errors, etc.

We may also have conflating factors. How do we just pick *one* variable?
* **Information Gain**
	* [Hartley Function](https://en.wikipedia.org/wiki/Hartley_function) - if the base of the logarithm is 2, then the unit of uncertainty is the *bit*. $$H(p) = \sum{-p\lg{p}}$$

No matter how much data we have, it's not all the data there is.

**Key Idea**: Information gain
* $H_0 =$ no info. This follows a $\chi^2$ distribution.
* This gives us *some* way of estimating what is and isn't noise.