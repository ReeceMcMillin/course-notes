---
title: "2022-11-30"
date: 2022-11-30
tags:
- lecture
- cs461
---

# Examples of Bias in AI

* Microsoft set up a Twitter bot that quickly became a Nazi

# Required Reading
1. [Excavating AI: The Politics of Images in Machine Learning Training Sets](https://excavating.ai/)
2. [Image Generation is Racist - MIT Tech Review](https://umsystem.instructure.com/courses/130082/files/12426654?module_item_id=4882855)
3. [Can the Biases in Facial Recognition Be Fixed; Also, Should They?](https://umsystem.instructure.com/courses/130082/files/12426632?module_item_id=4882856)
4. [Catherine D’Ignazio: 'Data is never a raw, truthful input – and it is never neutral'](https://www.theguardian.com/technology/2020/mar/21/catherine-dignazio-data-is-never-a-raw-truthful-input-and-it-is-never-neutral)
